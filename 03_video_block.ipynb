{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fastai.vision.all import *\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "from fastai.data.all import *\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import regex as re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_frames(video,start=0, end=5):\n",
    "    '''show frames in a video from start to end'''\n",
    "    for frame in video[start:end]:\n",
    "        clear_output(wait=True)\n",
    "        frame.show()\n",
    "        time.sleep(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Video(L):\n",
    "    ''' the init function takes a list of PILImage s'''  \n",
    "    @classmethod\n",
    "    def create(cls, paths:Union[list,str], sep='\\n'): \n",
    "        '''create images from frames path in a video'''\n",
    "        paths = paths.split(sep) if isinstance(paths, str) else paths\n",
    "        return cls(map(PILImage.create, paths))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResizeTime(Transform):\n",
    "    split_idx=None # 0- train 1- validation \n",
    "    def __init__(self, skip=2, l=50, drop_last=True): \n",
    "        self.skip = skip\n",
    "        self.l = l\n",
    "        self.drop_last = drop_last\n",
    "        \n",
    "    def encodes(self, vid:(list,str,Video), sep='\\n'):\n",
    "        '''create a list of frame-images (snippet) out a single video path'''\n",
    "        l, skip = self.l, self.skip\n",
    "        vid = vid.split(sep) if isinstance(vid, str) else vid # list of video\n",
    "        snippet_list = snippets_from_video(vid,s=skip,l=l)\n",
    "        idx = len(snippet_list)//2 if split_idx else random.randint(0,len(snippet_list)-1) # ** if validation always takes middle snip\n",
    "        return snippet_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@ToTensor\n",
    "def encodes(self, vid:Video):\n",
    "    img2tens=ToTensor()\n",
    "    return torch.cat([img2tens(frame)[None] for frame in vid])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_sz(x):\n",
    "    if isinstance(x, tuple): x = x[0]\n",
    "    if not isinstance(x, Tensor): return fastuple(x.size)\n",
    "    return fastuple(x.get_meta('img_size', x.get_meta('sz', (x.shape[-1], x.shape[-2]))))\n",
    "\n",
    "@Resize\n",
    "def encodes(self, video:Video):\n",
    "        nw_vid=[]\n",
    "        for frame in video:\n",
    "            orig_sz = _get_sz(frame)\n",
    "            w,h = orig_sz\n",
    "            op = (operator.lt,operator.gt)[self.method==ResizeMethod.Pad]\n",
    "            m = w/self.size[0] if op(w/self.size[0],h/self.size[1]) else h/self.size[1]\n",
    "            cp_sz = (int(m*self.size[0]),int(m*self.size[1]))\n",
    "            tl = fastuple(int(self.pcts[0]*(w-cp_sz[0])), int(self.pcts[1]*(h-cp_sz[1])))\n",
    "            fastaiImg = PILImage.create(np.array(frame.crop_pad(cp_sz, tl, orig_sz=orig_sz, pad_mode=self.pad_mode,\n",
    "                       resize_mode=self.mode_mask if isinstance(frame,PILMask) else self.mode, resize_to=self.size)))\n",
    "            nw_vid.append(fastaiImg)\n",
    "        return Video(nw_vid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def uniformize_dataset(vds, lbls, n=3, shuffle=True):\n",
    "    if shuffle: random.shuffle(lbls)\n",
    "    vocab = list(set(lbls))\n",
    "    lbl2vds = {lbl:[] for lbl in vocab}\n",
    "    for i, lbl in enumerate(lbls): lbl2vds[lbl].append(i)\n",
    "    idxs = []\n",
    "    while len(vocab)!=0:\n",
    "        lbl = random.choice(vocab)\n",
    "        for i in range(n):\n",
    "            try: \n",
    "                idx = lbl2vds[lbl].pop()\n",
    "                idxs.append(idx)\n",
    "            except IndexError:\n",
    "                vocab.remove(lbl)\n",
    "                break\n",
    "    return vds[idxs], lbls[idxs]  \n",
    "\n",
    "def get_vid_files(path:(Path, str), index_col=0, sep='\\n'):\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    vds = L([paths.split(sep) for paths in df['paths']])\n",
    "    lbls = df['lbl']\n",
    "    return uniformize_dataset(vds, lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UniformLabelsCallback(Callback):\n",
    "#     def __init__(self, path):\n",
    "#         super().__init__()\n",
    "#         self.path = path\n",
    "        \n",
    "    def after_epoc(self):\n",
    "        vds, lbls = uniformize_dataset(*self.dls.items)\n",
    "        dls = dls.new(bs=40)\n",
    "        #######\n",
    "        # Create new datasets and dataloaders from newly oredered items\n",
    "        #######\n",
    "        self.learn.dls = dls.new(items=(vds,lbls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_snippets(path_to_csv, col_name='paths', skip=3, l=25, sep='\\n'):\n",
    "        '''create a list of all snippets in path form'''\n",
    "        df=pd.read_csv(path_to_csv)\n",
    "        vds=[v.split(sep) for v in df[col_name]] #  list of frames in a list of all the videos\n",
    "        ll_snip=[snippets_from_video(el,l,skip) for el in vds] # list of videos cont list of snips cont list of frames \n",
    "        return [s for l_snip in ll_snip for s in l_snip] #flatten list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def snippets_from_video(vid, l=10, s=2):\n",
    "    '''create list of snippet out a video'''\n",
    "    vid=vid[::s] # skip frames\n",
    "    return [[vid[i] for i in range(k*l, k*l + l)] for k in range(0,len(vid)//l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp video_block"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
