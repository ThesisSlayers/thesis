# AUTOGENERATED! DO NOT EDIT! File to edit: 11_create_embeddings.ipynb (unless otherwise specified).

__all__ = ['initialize_tensors', 'iterate_over_videos', 'iterator_over_frames', 'snippet_is_ready', 'batch_is_ready',
           'get_and_save_embs', 'Snippet', 'fr_is_anomaly', 'add_snip_to_batch', 'create_embeddings',
           'rm_files_at_your_own_risk']

# Cell
from fastai.vision.all import *
import torchvision
import numpy as np
import torch
import cv2
import os
from .video_block import *
import random
import time
from pathlib import Path
import os
import pandas as pd

# Cell
def initialize_tensors(bs, l, size):
    fr_ts = torch.zeros(3, size, size, dtype=torch.float)
    snip = Snippet(l, size)
    xb = torch.zeros(bs, l, 3, size, size, dtype=torch.float)
    yb = torch.zeros(bs, dtype=torch.uint8)
    return fr_ts, snip, xb, yb

def iterate_over_videos(df):
    for k in range(len(df)):
        series = df.iloc[k]
        vid_path, start1, end1, start2, end2 = series.file, series.start1, series.end1, series.start2, series.end2
        vidcap = cv2.VideoCapture(str(vid_path))
        yield vidcap, vid_path, start1, end1, start2, end2
        vidcap.release()

def iterator_over_frames(vidcap, skip=2):
    duration = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)
    height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    width =  int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))
    l = int(duration//skip)
    frame = np.zeros((height,width,3), dtype=np.uint8)
    for frame_pos in range(0, l*skip, skip):
        vidcap.set(cv2.CAP_PROP_POS_FRAMES, frame_pos)
        res, frame[:] = vidcap.read()
        yield frame_pos, frame

def snippet_is_ready(i, l): return i==l-1
def batch_is_ready(j, bs): return j==bs

def get_and_save_embs(xb, yb, model, vid_path, save_path, snip_counter):
    vid_path = Path(vid_path)
    embs = model(xb.permute(0,2,1,3,4).float().cuda())
    #embs = torch.zeros(*xb.shape)
    path = save_path/vid_path.parent.stem/vid_path.stem
    path.mkdir(parents=True, exist_ok=True)
    for i, emb in enumerate(embs):
        torch.save(emb, path/f'{snip_counter:03d}_{yb[i]}.pth')
        snip_counter += 1

class Snippet():
    def __init__(self, l, size):
        self.x = torch.zeros(l, 3, size, size, dtype=float)
        self.l = l
        self.n_saved_frames = 0
        self.n_anomalous_frames = 0

    def add_frame(self, fr_ts, lbl_frame):
        self.x[self.n_saved_frames] = fr_ts
        self.n_saved_frames += 1
        self.n_anomalous_frames += lbl_frame

    def is_anomaly(self):
        if self.n_anomalous_frames >= self.l*0.5: return 1
        elif self.n_anomalous_frames >= self.l*0.2: return 2
        else: return 0

    def is_ready(self): return self.n_saved_frames==self.l

    def restart_counters(self):
        self.n_saved_frames, self.n_anomalous_frames = 0, 0

def fr_is_anomaly(n_fr, start, end):
    if start <= n_fr <= end: return 1
    else: return 0

def add_snip_to_batch(xb, yb, snip, j):
    xb[j], yb[j] = snip.x, snip.is_anomaly()
    snip.restart_counters()

def create_embeddings(df, model, pl, bs, size, l, skip, save_path):
    for vidcap, vid_path, start1, end1, start2, end2 in iterate_over_videos(df):
        fr_ts, snip, xb, yb = initialize_tensors(bs, l, size)
        j, snip_counter = 0, 0 # j contera' quanti snippets sono stati gia' messi nel batch
        for frame_pos, frame in iterator_over_frames(vidcap, skip=skip):
            fr_ts[:], fr_lbl = pl(frame), fr_is_anomaly(frame_pos, start1, end1) or fr_is_anomaly(frame_pos, start2, end2)
            snip.add_frame(fr_ts, fr_lbl)
            if snip.is_ready():
                add_snip_to_batch(xb, yb, snip, j)
                j += 1
            if batch_is_ready(j,bs):
                get_and_save_embs(xb, yb, model, vid_path, save_path, snip_counter)
                j, snip_counter = 0, snip_counter + bs

        if not batch_is_ready(j,bs): get_and_save_embs(xb[:j+1], yb[:j+1], model, vid_path, save_path, snip_counter)  # if the video didnt fill the last batch, save nevertheless the


# Cell
def rm_files_at_your_own_risk(path,fn=None,ext='.pth'):
    l = get_files(path,extensions=ext)
    l = l.filter(fn) if fn is not None else l
    l.map(os.remove)