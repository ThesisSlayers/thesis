# AUTOGENERATED! DO NOT EDIT! File to edit: 03_video_block.ipynb (unless otherwise specified).

__all__ = ['show_frames', 'Video', 'snippets_from_video', 'stretch', 'ResizeTime', 'encodes', 'encodes',
           'uniformize_dataset', 'UniformizedShuffle', 'DF2Paths']

# Cell
import torch
import torch.nn as nn
from fastai.vision.all import *
import time
from IPython.display import display, clear_output
from fastai.data.all import *
import pandas as pd
from pathlib import Path
import regex as re
import numpy as np
from collections.abc import Sequence


# Cell
def show_frames(video,start=0, end=5):
    '''show frames in a video from start to end'''
    for frame in video[start:end]:
        clear_output(wait=True)
        frame.show()
        time.sleep(0.5)


# Cell
@patch
def insert(l:L, i, o):
    l.items.insert(i, o)

class Video(L):
    ''' the init function takes a list of PILImage s'''
    @classmethod
    def create(cls, paths:(L,list,str), sep='\n'):
        '''create images from frames path in a video'''
        paths = paths.split(sep) if isinstance(paths, str) else paths
        return cls(map(PILImage.create, paths))

    def __mul__(self, n):
        neg = n < 0
        if n==0 or abs(n) >=1: return self[[(i+neg)//n for i in range(abs(int(n))*len(self))]]
        else: return self/(1/n)

    def __truediv__(self, n):
        n = int(n)
        return self[::n]

    def __rmul__(self, n):
        return self*n

    def __getitem__(self, idx): return self._get(idx) if is_indexer(idx) else Video(self._get(idx), use_list=None)


# Cell
def snippets_from_video(vid, l=10, s=2):
    '''create list of snippet out a video'''
    vid=vid[::s] # skip frames
    return [[vid[i] for i in range(k*l, k*l + l)] for k in range(0,len(vid)//l)]

def stretch(vid, l):
    vid = vid*(l//len(vid))
    if len(vid) == l: return vid
    lv = len(vid)
    n = l - lv                     # Number of frames to be inserted
    d = lv//n                      # Number of frames between inserted frames
    idxs = L(range(lv))
    for i in range(n):
        idxs.insert((d+1)*i, d*i)
    return vid[idxs]

class ResizeTime(Transform):
    split_idx = None # 0- train 1- validation
    def __init__(self, skip=2, l=50, drop_last=True,**kwargs):
        self.skip = skip
        self.l = l
        self.drop_last = drop_last
        super().__init__(**kwargs)

    def encodes(self, vid:Video, split_idx=split_idx):
        '''create a list of frame-images (snippet) out a single video path'''
        l, skip, l_vid = self.l, self.skip, len(vid)
        if l_vid > l:
#             snippet_list = snippets_from_video(vid,s=skip,l=l)
#             idx = len(snippet_list)//2 if split_idx else random.randint(0,len(snippet_list)-1) # ** if validation always takes middle snip
#             return snippet_list[idx]
            idx = (len(vid)-l)//2 if split_idx else random.randint(0,len(vid)-l) # ** if validation always takes middle snip
            return vid[idx:idx+l]

        else:
            vid = stretch(vid, l)
        return vid


# Cell
@ToTensor
def encodes(self, vid:Video):
    return vid.stack().float().permute(3,0,1,2)


# Cell
def _get_sz(x):
    if isinstance(x, tuple): x = x[0]
    if not isinstance(x, Tensor): return fastuple(x.size)
    return fastuple(x.get_meta('img_size', x.get_meta('sz', (x.shape[-1], x.shape[-2]))))

@Resize
def encodes(self, video:Video):
        nw_vid=[]
        for frame in video:
            orig_sz = _get_sz(frame)
            w,h = orig_sz
            op = (operator.lt,operator.gt)[self.method==ResizeMethod.Pad]
            m = w/self.size[0] if op(w/self.size[0],h/self.size[1]) else h/self.size[1]
            cp_sz = (int(m*self.size[0]),int(m*self.size[1]))
            tl = fastuple(int(self.pcts[0]*(w-cp_sz[0])), int(self.pcts[1]*(h-cp_sz[1])))
            fastaiImg = PILImage.create(np.array(frame.crop_pad(cp_sz, tl, orig_sz=orig_sz, pad_mode=self.pad_mode,
                       resize_mode=self.mode_mask if isinstance(frame,PILMask) else self.mode, resize_to=self.size)))
            nw_vid.append(fastaiImg)
        return Video(nw_vid)


# Cell
def uniformize_dataset(lbls, n_el=3, n_lbl=3, shuffle=True):
    vocab = list(set(lbls))
    lbl2idxs = {lbl:[] for lbl in vocab}
    for i, lbl in enumerate(lbls): lbl2idxs[lbl].append(i)
    if shuffle: [random.shuffle(v) for v in lbl2idxs.values()]
    idxs = []
    while len(vocab) >= n_lbl:
        lbl_samples = random.sample(vocab, n_lbl)
        for lbl in lbl_samples:
            for i in range(n_el):
                idx = lbl2idxs[lbl].pop()
                idxs.append(idx)
            if len(lbl2idxs[lbl]) <= n_el:
                vocab.remove(lbl)
    return idxs

# Cell
class UniformizedShuffle():
    def __init__(self, lbls, n_el=3, n_lbl=3):
        store_attr(self, 'lbls,n_el,n_lbl')

    def __call__ (self, x=None):
        return uniformize_dataset(lbls=self.lbls, n_el=self.n_el, n_lbl=self.n_lbl)


# Cell
class DF2Paths(Transform):
    def __init__(self, path, fps=24, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.path, self.fps = path, fps


    def encodes(self, df:pd.Series):
        def fr(t): return int(float(t)*self.fps)
        Id, start, end = df['id'], fr(df['start']) + 1, fr(df['end'])
        step = -1 if start > end else 1                     # If start is greater than end,
                                                            # it reverses the order of the for loop
                                                            # This because it seems some videos are in reverse

        def fr_path(n:int): return str(self.path/'Charades_v1_rgb'/Id/f'{Id}-{n:0>6d}.jpg')
        vid = [fr_path(n) for n in range(start, end, step) if os.path.exists(fr_path(n))]
        return vid