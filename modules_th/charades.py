# AUTOGENERATED! DO NOT EDIT! File to edit: 05_charades.ipynb (unless otherwise specified).

__all__ = ['read_data', 'get_datasets', 'get_dls', 'get_learner']

# Cell
import torch
import torch.nn as nn
from fastai.vision.all import *
from fastai.data.all import *
from fastai.distributed import *
import pandas as pd
from pathlib import Path
import time
from video_block import *
from inflator import *
from triplet_loss import *

# Cell
def read_data():
    path_data = '/mnt/data/adrianlopez/Videos/Charades/df.csv'
    df = pd.read_csv(path_data, index_col=0).dropna()
    return df

# Cell
def get_datasets(df, l, n_lbl, n_el):
    def get_vid_path(df:pd.Series): return Video(df['paths'].split('\n'))
    def get_lbls(df:pd.Series): return df['lbl']

    tfms = [[get_vid_path, ResizeTime(l=l), Video.create],
            [get_lbls, Categorize()]]

    splits = RandomSplitter(valid_pct=0.2, seed=42)(df)
    splits = [uniformize_dataset(idxs, df.iloc[idxs]['lbl'] , n_lbl=n_lbl, n_el=n_el) for idxs in splits]

    dsets = Datasets(df, tfms, splits=splits)
    return dsets

# Cell
def get_dls(df, sz, l, n_lbl, n_el):
    dsets = get_datasets(df, l, n_lbl, n_el)
    dls = dsets.dataloaders(bs=n_el*n_lbl,
                            device=torch.device('cuda:1'),
                            shuffle_train=False,
                            after_item=[Resize(sz), ToTensor()],
                            after_batch=[IntToFloatTensor(), Normalize.from_stats(*imagenet_stats)])
    return dls

# Cell
def get_learner(df, l, sz, n_lbl, n_el):
    dls = get_dls(df, sz, l, n_lbl, n_el)
    head, body = inflate(create_head(1024, len(dls.vocab), lin_ftrs=[256])), inflate(create_body(resnet34, cut=-2))
    learn = Learner(dls,
    #                 NullModel(),
                    TLModel(body,head),
    #                 loss_func=NullLoss(),
                    MixedLoss(alpha=1.0, margin=.2),
    #                 splitter=null_splitter,
                    splitter=my_splitter,
    #                 opt=Optimizer([0], noop),
    #                 metrics=lambda *x: 0)
                    metrics=tl_accuracy)
    return learn

# Internal Cell
df = read_data()
learn = get_learner(df, l=10, sz=128, n_lbl=4, n_el=8)
learn.fine_tune(1)