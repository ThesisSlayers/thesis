{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DF2Paths():\n",
    "    def __init__(self, path, fps=24):\n",
    "        self.path, self.fps = path, fps\n",
    "        \n",
    "    def __call__(self, item:pd.Series):\n",
    "        def fr(t): return int(float(t)*self.fps)\n",
    "    \n",
    "        Id, start, end = item['id'], item['start'], item['end']\n",
    "        start, end = fr(start), fr(end)\n",
    "        step = -1 if start > end else 1                     # If start is greater than end,\n",
    "                                                            # it reverses the order of the for loop\n",
    "        vid = L()                                           # This because it seems some videos are in reverse\n",
    "        for n in range(start, end, step):\n",
    "            fr_path = self.path/'Charades_v1_rgb'/Id/f'{Id}-{n:0>6d}.jpg'\n",
    "            if os.path.exists(fr_path):\n",
    "                vid.append(fr_path)\n",
    "        return vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delegates()\n",
    "class UniformizedDataLoader(TfmdDL): \n",
    "    def __init__(self, dataset=None, n_el=4, n_lbl=4, **kwargs):\n",
    "        kwargs['bs'] = n_el*n_lbl\n",
    "        super().__init__(dataset, **kwargs)\n",
    "        store_attr(self, 'n_el,n_lbl')\n",
    "        self.lbls = list(map(int, self.dataset.tls[1]))\n",
    "        self.dl_vocab = list(range(len(self.vocab)))\n",
    "        \n",
    "    def before_iter(self):\n",
    "        super().before_iter()\n",
    "        lbl2idxs = {lbl:[] for lbl in self.dl_vocab}\n",
    "        for i, lbl in enumerate(self.lbls): lbl2idxs[lbl].append(i)\n",
    "        \n",
    "        if self.shuffle: [random.shuffle(v) for v in lbl2idxs.values()]\n",
    "        self.lbl2idxs = lbl2idxs\n",
    "        \n",
    "    def get_labeled_elements(self, lbl, n_el):\n",
    "        els_of_lbl = []\n",
    "        while len(els_of_lbl) < n_el:\n",
    "            item = self.do_item(self.lbl2idxs[lbl].pop())\n",
    "            if item is not None: els_of_lbl.append(item) \n",
    "        return els_of_lbl\n",
    "        \n",
    "    def create_batches(self, samps):\n",
    "        n_lbl, n_el = self.n_lbl, self.n_el\n",
    "        self.it = iter(self.dataset) if self.dataset is not None else None\n",
    "        \n",
    "        while len(self.dl_vocab) >= n_lbl:\n",
    "            \n",
    "            batch_lbls, b = [], []\n",
    "            \n",
    "            while len(batch_lbls) < n_lbl:\n",
    "                try: i = random.randint(0, len(self.dl_vocab) - 1)\n",
    "                except ValueError: raise CancelBatchException\n",
    "                lbl = self.dl_vocab.pop(i)\n",
    "                if len(self.lbl2idxs[lbl]) < n_lbl: continue\n",
    "                \n",
    "                try: els_of_lbl = self.get_labeled_elements(lbl, n_el)\n",
    "                except IndexError: continue\n",
    "                    \n",
    "                b.extend(els_of_lbl)\n",
    "                batch_lbls.append(lbl)\n",
    "                \n",
    "            self.dl_vocab.extend(batch_lbls)\n",
    "            \n",
    "            yield self.do_batch(b)\n",
    "            \n",
    "        self.dl_vocab = list(range(len(self.vocab)))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def uniformize_dataset(items, lbls, vocab=None, n_el=3, n_lbl=3, shuffle=True):\n",
    "    if vocab is None: vocab = list(set(lbls))\n",
    "    lbl2idxs = {lbl:[] for lbl in vocab}\n",
    "    for i, lbl in enumerate(lbls): lbl2idxs[lbl].append(i)\n",
    "    for lbl, idxs in lbl2idxs.items(): \n",
    "        if len(idxs) < n_el: vocab.remove(lbl)       \n",
    "    if shuffle: [random.shuffle(v) for v in lbl2idxs.values()]\n",
    "    idxs = []\n",
    "    while len(vocab) >= n_lbl:\n",
    "        lbl_samples = random.sample(vocab, n_lbl)\n",
    "        for lbl in lbl_samples:\n",
    "            i = 0\n",
    "            while i < n_el:\n",
    "                i += 1\n",
    "                idx = lbl2idxs[lbl].pop()\n",
    "                idxs.append(idx)\n",
    "            if len(lbl2idxs[lbl]) <= n_el:\n",
    "                vocab.remove(lbl)\n",
    "    return getattr(items, 'iloc', items)[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(path_charades/'df0.csv', index_col=0)\n",
    "items = uniformize_dataset(items, items['lbl'])\n",
    "items.tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UniformizedShuffle():\n",
    "    def __init__(self, lbls, vocab=None, n_el=4, n_lbl=4):\n",
    "        self.lbls = lbls\n",
    "        if vocab is None: vocab = list(set(lbls))\n",
    "        self.vocab = vocab\n",
    "        self.n_el = n_el\n",
    "        self.n_lbl = n_lbl\n",
    "    def __call__ (self, items):\n",
    "        return uniformize_dataset(items, lbls=self.lbls, vocab=self.vocab, n_el=self.n_el, n_lbl=self.n_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-92619e0b1819>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_charades\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'df0.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUniformizedShuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lbl'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path_charades/'df0.csv', index_col=0)\n",
    "un = UniformizedShuffle(items['lbl'])\n",
    "un(items).tail(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
