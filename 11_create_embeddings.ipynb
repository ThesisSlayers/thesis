{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import torchvision \n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "from modules_th.video_block import *\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.43216, 0.394666, 0.37645]\n",
    "std = [0.22803, 0.22145, 0.216989]\n",
    "\n",
    "model = create_body(torchvision.models.video.r2plus1d_18, cut=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vid_files</th>\n",
       "      <th>lbls</th>\n",
       "      <th>val</th>\n",
       "      <th>embs_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/data/eugeniomarinelli/UCF_Crimes/Videos/RoadAccidents/RoadAccidents140_x264.mp4</td>\n",
       "      <td>RoadAccidents</td>\n",
       "      <td>False</td>\n",
       "      <td>/mnt/data/eugeniomarinelli/UCF_Crimes/Videos/RoadAccidents/RoadAccidents140_x264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              vid_files  \\\n",
       "1  /mnt/data/eugeniomarinelli/UCF_Crimes/Videos/RoadAccidents/RoadAccidents140_x264.mp4   \n",
       "\n",
       "            lbls    val  \\\n",
       "1  RoadAccidents  False   \n",
       "\n",
       "                                                                          embs_path  \n",
       "1  /mnt/data/eugeniomarinelli/UCF_Crimes/Videos/RoadAccidents/RoadAccidents140_x264  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_df = '/mnt/data/eugeniomarinelli/UCF_experiments/training_cnn_ucf.csv'\n",
    "df = pd.read_csv(path_df, index_col=0)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2ebe47b7dbe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvid_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/data/eugeniomarinelli/UCF_Crimes/Videos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvid_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcreate_video_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_interface__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-718e730ebac3>\u001b[0m in \u001b[0;36mcreate_video_generator\u001b[0;34m(vid_path, skip)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mframe_pos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mvidcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvidcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vid_paths = get_files('/mnt/data/eugeniomarinelli/UCF_Crimes/Videos', extensions='.mp4')\n",
    "vid_path = random.choice(vid_paths)\n",
    "for frame in create_video_generator(vid_path):\n",
    "    print(frame.__array_interface__['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_tensors(bs, l, size):\n",
    "    fr_ts = torch.zeros(3, size, size, dtype=float)\n",
    "    snip = torch.zeros(l, 3, size, size, dtype=float)\n",
    "    b = torch.zeros(bs, l, 3, size, size, dtype=float)\n",
    "    return fr_ts, snip, b\n",
    "\n",
    "def iterate_with_vidcap(vid_paths):\n",
    "    for vid_path in vid_paths:\n",
    "        vidcap = cv2.VideoCapture(str(vid_path))\n",
    "        yield vidcap, vid_path\n",
    "        vidcap.release()\n",
    "\n",
    "def iterator_over_frames(vidcap, skip=2):\n",
    "    vidcap = cv2.VideoCapture(str(vid_path))\n",
    "    duration = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width =  int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    l = int(duration//skip)\n",
    "    frame = np.zeros((height,width,3), dtype=np.uint8)\n",
    "    for frame_pos in range(0, l*skip, skip):\n",
    "        vidcap.set(cv2.CAP_PROP_POS_FRAMES, frame_pos)\n",
    "        res, frame[:] = vidcap.read()\n",
    "        yield frame        \n",
    "        \n",
    "def snippet_is_ready(i, l): return i==l-1\n",
    "def batch_is_ready(i, l, j, bs): j==bs-1\n",
    "        \n",
    "def get_and_save_embs(b, model, path):\n",
    "    embs = model(b)\n",
    "    for emb in embs:\n",
    "         torch.save(emb, path) ### REMEMBER TO PUT PATH!!\n",
    "\n",
    "def create_embeddings(vid_paths, model, pl, bs, size, l, skip):\n",
    "    fr_ts, snip, b = initialize_tensors(bs, l, size)\n",
    "    for vidcap, vid_path in iterate_with_vidcap(vid_paths):        \n",
    "        j = 0 # j contera' quanti snippets sono stati gia' messi nel batch       \n",
    "        for n_fr, frame in iterator_over_frames(vidcap, skip=skip):\n",
    "            i, n_sn = n_fr%l,  n_fr//l  # i contera' il # di frames messo nello snippet, n_sn e' il numero di snips creati finora             \n",
    "            fr_ts[:] = pl(frame)\n",
    "            snip[i] = fr_ts\n",
    "            if snippet_is_ready(i,l): b[j] = snip; j += 1 \n",
    "            if batch_is_ready(j,bs): get_and_save_embs(b,path); j = 0\n",
    "        if not batch_is_ready(j,bs): get_and_save_embs(b, path)  # if the video didnt fill the last batch, save nevertheless the \n",
    "                                                                 # last created snipets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, size, l, skip = 16, 224, 50, 2\n",
    "pl = Pipeline([PILImage.create,\n",
    "               Resize(size, method=ResizeMethod.Pad), \n",
    "               ToTensor(), \n",
    "               IntToFloatTensor(), \n",
    "               Normalize.from_stats(mean,std)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_frame_to_snip(res, frame, snip, j):\n",
    "    if res: \n",
    "        snip[j] = tensor(frame)\n",
    "        j += 1\n",
    "    return snip, j\n",
    "\n",
    "def snip_is_ready(j, sl):\n",
    "    return j >= sl\n",
    "\n",
    "def create_and_save_embs(snip, pl, embs_path, k):\n",
    "    emb = model(pl(snip)[None])\n",
    "    torch.save(emb, embs_path/f'{embs_path.name}_{k}.pt') # save embeddings  \n",
    "    return k + 1\n",
    "\n",
    "def get_embs_of_video(vid_path, sl, size):    \n",
    "    vidcap = cv2.VideoCapture(str(random.choice(vid_paths)))\n",
    "    duration = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        n_loaded_frames, n_created_embs = 0, 0  # j counts # of frames loaded mod sl, k counts # of snippets\n",
    "        snip = torch.zeros((sl,240,320,3), dtype=torch.uint8)\n",
    "        for i in range(duration):\n",
    "            if duration - i < sl: break\n",
    "            res, frame = vidcap.read()\n",
    "            snip, j = add_frame_to_snip(res, frame, snip, j)\n",
    "            if snip_is_ready(j, sl): \n",
    "                k = create_and_save_embs(snip, pl, '', k)\n",
    "                j = 0\n",
    "\n",
    "    vidcap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221.89058896782808"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl, size = 16, 60, 224\n",
    "pl = Pipeline([Video.create, \n",
    "               Resize(size,method=ResizeMethod.Pad), \n",
    "               ToTensor(), \n",
    "               IntToFloatTensor(), \n",
    "               Normalize.from_stats(mean,std)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.333333333333333"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "440/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8697916666666667"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration/sl/bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1mnt/data/eugeniomarinelli/UCF_Crimes/Videos/Testing_Normal_Videos_Anomaly/Normal_Videos_903_x264\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-ea47d2630e30>:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.embs_path[j] = str(embs_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23nt/data/eugeniomarinelli/UCF_Crimes/Videos/Training_Normal_Videos_Anomaly/Normal_Videos384_x264\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98nt/data/eugeniomarinelli/UCF_Crimes/Videos/Robbery/Robbery086_x264Anomaly/Normal_Videos501_x264\r"
     ]
    }
   ],
   "source": [
    "bs, sl, size = 16, 60, 224\n",
    "pl = Pipeline([Video.create, \n",
    "               Resize(size,method=ResizeMethod.Pad), \n",
    "               ToTensor(), \n",
    "               IntToFloatTensor(), \n",
    "               Normalize.from_stats(mean,std)])\n",
    "\n",
    "for j, path in enumerate(vid_paths):\n",
    "#        if isinstance(df.embs_path.values[j],str) : continue; # start where we left\n",
    "    print(j, end='\\r')\n",
    "    embs_path = Path(path[:-4]) # path to save emb video snippets \n",
    "    if not os.path.isdir(embs_path): os.mkdir(embs_path) # make folder\n",
    "\n",
    "    vidcap = cv2.VideoCapture(path)\n",
    "    duration = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        j, k = 0, 0  # j counts # of frames loaded mod sl, k counts # of snippets\n",
    "        snip = torch.zeros((sl,240,320,3), dtype=torch.uint8)\n",
    "        for i in range(duration):\n",
    "            if duration - i < sl: break\n",
    "            res, frame = vidcap.read()\n",
    "            snip, j = add_frame_to_snip(res, frame, snip, j)\n",
    "            if snip_is_ready(j, sl): \n",
    "                k = create_and_save_embs(snip, pl, '', k)\n",
    "                j = 0\n",
    "\n",
    "    vidcap.release()\n",
    "            df.embs_path[j] = str(embs_path)\n",
    "            df.to_csv(path_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1mnt/data/eugeniomarinelli/UCF_Crimes/Videos/Testing_Normal_Videos_Anomaly/Normal_Videos_903_x264\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-ea47d2630e30>:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.embs_path[j] = str(embs_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23nt/data/eugeniomarinelli/UCF_Crimes/Videos/Training_Normal_Videos_Anomaly/Normal_Videos384_x264\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98nt/data/eugeniomarinelli/UCF_Crimes/Videos/Robbery/Robbery086_x264Anomaly/Normal_Videos501_x264\r"
     ]
    }
   ],
   "source": [
    "sl = 32\n",
    "bs = 8\n",
    "int2f = IntToFloatTensor()\n",
    "pl = Pipeline([Resize(224, method=ResizeMethod.Pad),ToTensor(),IntToFloatTensor(), Normalize.from_stats(mean,std)])\n",
    "with torch.no_grad(): \n",
    "    for j, path in enumerate(vid_paths):\n",
    "#        if isinstance(df.embs_path.values[j],str) : continue; # start where we left\n",
    "        print(j, end='\\r')\n",
    "        embs_path = Path(path[:-4]) # path to save emb video snippets \n",
    "        if not os.path.isdir(embs_path): os.mkdir(embs_path) # make folder\n",
    "        times = L(L(), L(), L())\n",
    "        i = 0\n",
    "        for start in range(0, int(duration)-sl*bs, sl*bs):\n",
    "            l = duration - duration%(sl*bs) if duration < sl*bs else sl*bs\n",
    "            \n",
    "            t0 = time.perf_counter()\n",
    "            snips = create_video(path, start = start, l=l, skip=1, form='img')\n",
    "            times[0].append(time.perf_counter()-t0)\n",
    "            \n",
    "            snips = L(chunked(snips, sl)).map(Video).map(pl).stack()       \n",
    "            \n",
    "            t1 = time.perf_counter()\n",
    "            embs = model(snips.cuda())\n",
    "            times[1].append(time.perf_counter()-t1)\n",
    "            \n",
    "            t2 = time.perf_counter()\n",
    "            for emb in embs:\n",
    "                torch.save(emb, embs_path/f'{embs_path.name}_{i}.pt') # save embeddings\n",
    "                i +=1\n",
    "            times[2].append(time.perf_counter()-t2)\n",
    "            \n",
    "        print(embs_path, end='\\r')\n",
    "        df.embs_path[j] = str(embs_path)\n",
    "        df.to_csv(path_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Normal_Videos437_x264.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_files('/mnt/data/eugeniomarinelli/UCF_Crimes/Video', extensions='.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 3, 32, 224, 224)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(chunked(snips, sl)).map(Video).map(pl).stack().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#76600) [None,None,None,None,None,None,None,None,None,None...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = get_files('/mnt/data/eugeniomarinelli/UCF_Crimes/Videos',extensions='.pt')\n",
    "files.map(os.remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
