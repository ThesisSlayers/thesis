{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import torchvision \n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "from modules_th.video_block import *\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.43216, 0.394666, 0.37645]\n",
    "std = [0.22803, 0.22145, 0.216989]\n",
    "\n",
    "model = create_body(torchvision.models.video.r2plus1d_18, cut=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vid_files</th>\n",
       "      <th>lbls</th>\n",
       "      <th>val</th>\n",
       "      <th>embs_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/data/eugeniomarinelli/UCF_Crimes/Videos/RoadAccidents/RoadAccidents140_x264.mp4</td>\n",
       "      <td>RoadAccidents</td>\n",
       "      <td>False</td>\n",
       "      <td>/mnt/data/eugeniomarinelli/UCF_Crimes/Videos/RoadAccidents/RoadAccidents140_x264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              vid_files  \\\n",
       "1  /mnt/data/eugeniomarinelli/UCF_Crimes/Videos/RoadAccidents/RoadAccidents140_x264.mp4   \n",
       "\n",
       "            lbls    val  \\\n",
       "1  RoadAccidents  False   \n",
       "\n",
       "                                                                          embs_path  \n",
       "1  /mnt/data/eugeniomarinelli/UCF_Crimes/Videos/RoadAccidents/RoadAccidents140_x264  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_df = '/mnt/data/eugeniomarinelli/UCF_experiments/training_cnn_ucf.csv'\n",
    "df = pd.read_csv(path_df, index_col=0)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_paths = df.vid_files.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_generator(vid_path, skip=2):\n",
    "    vidcap = cv2.VideoCapture(str(vid_path))\n",
    "    duration = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width =  int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    l = int(duration//skip)\n",
    "    frame = np.zeros((height,width,3), dtype=np.uint8)\n",
    "    for frame_pos in range(0, l*skip, skip):\n",
    "        vidcap.set(cv2.CAP_PROP_POS_FRAMES, frame_pos)\n",
    "        res, frame[:] = vidcap.read()\n",
    "        yield frame         \n",
    "    vidcap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n",
      "94175458341728\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-2ebe47b7dbe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvid_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/data/eugeniomarinelli/UCF_Crimes/Videos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvid_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcreate_video_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_interface__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-718e730ebac3>\u001b[0m in \u001b[0;36mcreate_video_generator\u001b[0;34m(vid_path, skip)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mframe_pos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mvidcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvidcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vid_paths = get_files('/mnt/data/eugeniomarinelli/UCF_Crimes/Videos', extensions='.mp4')\n",
    "vid_path = random.choice(vid_paths)\n",
    "for frame in create_video_generator(vid_path):\n",
    "    print(frame.__array_interface__['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-538cbd35b205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                \u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                \u001b[0mIntToFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                Normalize.from_stats(mean,std)])\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/VE/lib/python3.7/site-packages/fastai/data/transforms.py\u001b[0m in \u001b[0;36mfrom_stats\u001b[0;34m(cls, mean, std, dim, ndim, cuda)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbroadcast_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/VE/lib/python3.7/site-packages/fastai/data/transforms.py\u001b[0m in \u001b[0;36mbroadcast_vec\u001b[0;34m(dim, ndim, cuda, *t)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_device\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnoop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/VE/lib/python3.7/site-packages/fastai/data/transforms.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_device\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnoop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/VE/lib/python3.7/site-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36mto_device\u001b[0;34m(b, device)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_inner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_device\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/VE/lib/python3.7/site-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(func, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mretain_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/VE/lib/python3.7/site-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36m_inner\u001b[0;34m(o)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_inner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_device\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_and_save_embs(b, path):\n",
    "    embs = model(b)\n",
    "    for emb in embs.unbind():\n",
    "         torch.save(emb, path) ### REMEMBER TO PUT PATH!!\n",
    "\n",
    "bs, size, l, skip = 16, 224, 50, 2\n",
    "pl = Pipeline([PILImage.create,\n",
    "               Resize(size,method=ResizeMethod.Pad), \n",
    "               ToTensor(), \n",
    "               IntToFloatTensor(), \n",
    "               Normalize.from_stats(mean,std)])\n",
    "\n",
    "shape = bs, l, 3, size, size\n",
    "fr_ts = torch.zeros(*shape[2:], dtype=float)\n",
    "snip = torch.zeros(*shape[1:], dtype=float)\n",
    "b = torch.zeros(*shape, dtype=float)\n",
    "\n",
    "for vid in vid_paths:\n",
    "    for i, frame in create_video_generator(vid_path, skip=2):\n",
    "        n_fr, n_snip = i%l, (i//l)%bs \n",
    "        fr_ts[:] = pl(frame)\n",
    "        snip[n_fr] = fr_ts\n",
    "        if n_fr==l-1: b[n_snip] = snip\n",
    "        if n_snip==bs-1: get_and_save_embs(b, path) ### REMEMBER TO CHANGE PATH IN THE FUNCTION!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_frame_to_snip(res, frame, snip, j):\n",
    "    if res: \n",
    "        snip[j] = tensor(frame)\n",
    "        j += 1\n",
    "    return snip, j\n",
    "\n",
    "def snip_is_ready(j, sl):\n",
    "    return j >= sl\n",
    "\n",
    "def create_and_save_embs(snip, pl, embs_path, k):\n",
    "    emb = model(pl(snip)[None])\n",
    "    torch.save(emb, embs_path/f'{embs_path.name}_{k}.pt') # save embeddings  \n",
    "    return k + 1\n",
    "\n",
    "def get_embs_of_video(vid_path, sl, size):    \n",
    "    vidcap = cv2.VideoCapture(str(random.choice(vid_paths)))\n",
    "    duration = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        n_loaded_frames, n_created_embs = 0, 0  # j counts # of frames loaded mod sl, k counts # of snippets\n",
    "        snip = torch.zeros((sl,240,320,3), dtype=torch.uint8)\n",
    "        for i in range(duration):\n",
    "            if duration - i < sl: break\n",
    "            res, frame = vidcap.read()\n",
    "            snip, j = add_frame_to_snip(res, frame, snip, j)\n",
    "            if snip_is_ready(j, sl): \n",
    "                k = create_and_save_embs(snip, pl, '', k)\n",
    "                j = 0\n",
    "\n",
    "    vidcap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221.89058896782808"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl, size = 16, 60, 224\n",
    "pl = Pipeline([Video.create, \n",
    "               Resize(size,method=ResizeMethod.Pad), \n",
    "               ToTensor(), \n",
    "               IntToFloatTensor(), \n",
    "               Normalize.from_stats(mean,std)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.333333333333333"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "440/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8697916666666667"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration/sl/bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1mnt/data/eugeniomarinelli/UCF_Crimes/Videos/Testing_Normal_Videos_Anomaly/Normal_Videos_903_x264\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-ea47d2630e30>:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.embs_path[j] = str(embs_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23nt/data/eugeniomarinelli/UCF_Crimes/Videos/Training_Normal_Videos_Anomaly/Normal_Videos384_x264\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98nt/data/eugeniomarinelli/UCF_Crimes/Videos/Robbery/Robbery086_x264Anomaly/Normal_Videos501_x264\r"
     ]
    }
   ],
   "source": [
    "bs, sl, size = 16, 60, 224\n",
    "pl = Pipeline([Video.create, \n",
    "               Resize(size,method=ResizeMethod.Pad), \n",
    "               ToTensor(), \n",
    "               IntToFloatTensor(), \n",
    "               Normalize.from_stats(mean,std)])\n",
    "\n",
    "for j, path in enumerate(vid_paths):\n",
    "#        if isinstance(df.embs_path.values[j],str) : continue; # start where we left\n",
    "    print(j, end='\\r')\n",
    "    embs_path = Path(path[:-4]) # path to save emb video snippets \n",
    "    if not os.path.isdir(embs_path): os.mkdir(embs_path) # make folder\n",
    "\n",
    "    vidcap = cv2.VideoCapture(path)\n",
    "    duration = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        j, k = 0, 0  # j counts # of frames loaded mod sl, k counts # of snippets\n",
    "        snip = torch.zeros((sl,240,320,3), dtype=torch.uint8)\n",
    "        for i in range(duration):\n",
    "            if duration - i < sl: break\n",
    "            res, frame = vidcap.read()\n",
    "            snip, j = add_frame_to_snip(res, frame, snip, j)\n",
    "            if snip_is_ready(j, sl): \n",
    "                k = create_and_save_embs(snip, pl, '', k)\n",
    "                j = 0\n",
    "\n",
    "    vidcap.release()\n",
    "            df.embs_path[j] = str(embs_path)\n",
    "            df.to_csv(path_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1mnt/data/eugeniomarinelli/UCF_Crimes/Videos/Testing_Normal_Videos_Anomaly/Normal_Videos_903_x264\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-ea47d2630e30>:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.embs_path[j] = str(embs_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23nt/data/eugeniomarinelli/UCF_Crimes/Videos/Training_Normal_Videos_Anomaly/Normal_Videos384_x264\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n",
      "mb_type 61 in P slice too large at 13 9\n",
      "error while decoding MB 13 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98nt/data/eugeniomarinelli/UCF_Crimes/Videos/Robbery/Robbery086_x264Anomaly/Normal_Videos501_x264\r"
     ]
    }
   ],
   "source": [
    "sl = 32\n",
    "bs = 8\n",
    "int2f = IntToFloatTensor()\n",
    "pl = Pipeline([Resize(224, method=ResizeMethod.Pad),ToTensor(),IntToFloatTensor(), Normalize.from_stats(mean,std)])\n",
    "with torch.no_grad(): \n",
    "    for j, path in enumerate(vid_paths):\n",
    "#        if isinstance(df.embs_path.values[j],str) : continue; # start where we left\n",
    "        print(j, end='\\r')\n",
    "        embs_path = Path(path[:-4]) # path to save emb video snippets \n",
    "        if not os.path.isdir(embs_path): os.mkdir(embs_path) # make folder\n",
    "        times = L(L(), L(), L())\n",
    "        i = 0\n",
    "        for start in range(0, int(duration)-sl*bs, sl*bs):\n",
    "            l = duration - duration%(sl*bs) if duration < sl*bs else sl*bs\n",
    "            \n",
    "            t0 = time.perf_counter()\n",
    "            snips = create_video(path, start = start, l=l, skip=1, form='img')\n",
    "            times[0].append(time.perf_counter()-t0)\n",
    "            \n",
    "            snips = L(chunked(snips, sl)).map(Video).map(pl).stack()       \n",
    "            \n",
    "            t1 = time.perf_counter()\n",
    "            embs = model(snips.cuda())\n",
    "            times[1].append(time.perf_counter()-t1)\n",
    "            \n",
    "            t2 = time.perf_counter()\n",
    "            for emb in embs:\n",
    "                torch.save(emb, embs_path/f'{embs_path.name}_{i}.pt') # save embeddings\n",
    "                i +=1\n",
    "            times[2].append(time.perf_counter()-t2)\n",
    "            \n",
    "        print(embs_path, end='\\r')\n",
    "        df.embs_path[j] = str(embs_path)\n",
    "        df.to_csv(path_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Normal_Videos437_x264.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_files('/mnt/data/eugeniomarinelli/UCF_Crimes/Video', extensions='.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 3, 32, 224, 224)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(chunked(snips, sl)).map(Video).map(pl).stack().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#76600) [None,None,None,None,None,None,None,None,None,None...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = get_files('/mnt/data/eugeniomarinelli/UCF_Crimes/Videos',extensions='.pt')\n",
    "files.map(os.remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
