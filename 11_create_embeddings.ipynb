{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import torchvision \n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "from modules_th.video_block import *\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.43216, 0.394666, 0.37645]\n",
    "std = [0.22803, 0.22145, 0.216989]\n",
    "\n",
    "model = create_body(torchvision.models.video.r2plus1d_18, cut=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n",
      "94865077762896\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2ebe47b7dbe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvid_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/data/eugeniomarinelli/UCF_Crimes/Videos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvid_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcreate_video_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_interface__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-718e730ebac3>\u001b[0m in \u001b[0;36mcreate_video_generator\u001b[0;34m(vid_path, skip)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mframe_pos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mvidcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvidcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vid_paths = get_files('/mnt/data/eugeniomarinelli/UCF_Crimes/Videos', extensions='.mp4')\n",
    "vid_path = random.choice(vid_paths)\n",
    "for frame in create_video_generator(vid_path):\n",
    "    print(frame.__array_interface__['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_tensors(bs, l, size):\n",
    "    fr_ts = torch.zeros(3, size, size, dtype=float)\n",
    "    snip = torch.zeros(l, 3, size, size, dtype=float)\n",
    "    b = torch.zeros(bs, l, 3, size, size, dtype=float)\n",
    "    return fr_ts, snip, b\n",
    "\n",
    "def iterate_with_vidcap(vid_paths):\n",
    "    for vid_path in vid_paths:\n",
    "        vidcap = cv2.VideoCapture(str(vid_path))\n",
    "        yield vidcap, vid_path\n",
    "        vidcap.release()\n",
    "\n",
    "def iterator_over_frames(vidcap, skip=2):\n",
    "    vidcap = cv2.VideoCapture(str(vid_path))\n",
    "    duration = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width =  int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    l = int(duration//skip)\n",
    "    frame = np.zeros((height,width,3), dtype=np.uint8)\n",
    "    for frame_pos in range(0, l*skip, skip):\n",
    "        vidcap.set(cv2.CAP_PROP_POS_FRAMES, frame_pos)\n",
    "        res, frame[:] = vidcap.read()\n",
    "        yield frame        \n",
    "        \n",
    "def snippet_is_ready(i, l): return i==l-1\n",
    "def batch_is_ready(i, l, j, bs): j==bs-1\n",
    "        \n",
    "def get_and_save_embs(b, model, path):\n",
    "    embs = model(b)\n",
    "    for emb in embs:\n",
    "         torch.save(emb, path) ### REMEMBER TO PUT PATH!!\n",
    "\n",
    "def create_embeddings(vid_paths, model, pl, bs, size, l, skip):\n",
    "    fr_ts, snip, b = initialize_tensors(bs, l, size)\n",
    "    for vidcap, vid_path in iterate_with_vidcap(vid_paths):        \n",
    "        j = 0 # j contera' quanti snippets sono stati gia' messi nel batch       \n",
    "        for n_fr, frame in iterator_over_frames(vidcap, skip=skip):\n",
    "            i, n_sn = n_fr%l,  n_fr//l  # i contera' il # di frames messo nello snippet, n_sn e' il numero di snips creati finora             \n",
    "            fr_ts[:] = pl(frame)\n",
    "            snip[i] = fr_ts\n",
    "            if snippet_is_ready(i,l): b[j] = snip; j += 1 \n",
    "            if batch_is_ready(j,bs): get_and_save_embs(b,path); j = 0\n",
    "        if not batch_is_ready(j,bs): get_and_save_embs(b, path)  # if the video didnt fill the last batch, save nevertheless the \n",
    "                                                                 # last created snipets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#76600) [None,None,None,None,None,None,None,None,None,None...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = get_files('/mnt/data/eugeniomarinelli/UCF_Crimes/Videos',extensions='.pt')\n",
    "files.map(os.remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
